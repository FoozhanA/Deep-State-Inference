{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from tqdm import notebook as tqdm\n",
    "except ImportError:\n",
    "    tqdm = None\n",
    "    \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import dataset_ops\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # show all columns\n",
    "GPUs = tf.config.list_physical_devices('GPU')\n",
    "if GPUs is None or len(GPUs) == 0:\n",
    "    print(\"WARNING: No GPU, all there is is:\")\n",
    "    for device in tf.config.list_physical_devices():\n",
    "        print(f'- {device}')\n",
    "else:\n",
    "    for gpu in GPUs:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Initialized\", gpu)\n",
    "\n",
    "dataset_manager = dataset_ops.TestsManager(dataset_dir='./h5', runs_filename='runs.hdf')\n",
    "all_runs = dataset_manager.get_all_available_tests()\n",
    "\n",
    "selected_runs = all_runs.loc[(all_runs['Test Length'] > 200) & (all_runs['Test Length'] < 20000)]\n",
    "# selected_runs = selected_runs.iloc[:40]\n",
    "# plt = selected_runs['Test Length'].plot(kind='hist', bins=15)\n",
    "# plt.set_xlabel('# Samples')\n",
    "# plt.set_ylabel('# Tests')\n",
    "# #selected_runs\n",
    "# print(all_runs.shape, selected_runs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inputs = ('SpeedFts', 'Pitch', 'Roll', 'Yaw', 'current_altitude', )\n",
    "outputs= ('elev', 'ai', 'rdr', 'throttle', 'Flaps')\n",
    "\n",
    "# max_length = selected_runs['Test Length'].max()\n",
    "# max_length = 18000 \n",
    "\n",
    "# dataset_manager.preload_data(selected_runs, max_length=max_length, features=inputs + outputs)\n",
    "# tfdataset = dataset_ops.TensorflowDataset(dataset_manager)\n",
    "# dataset = tfdataset.get_dataset(selected_runs, batch_size=25, features=inputs+outputs, max_length=max_length)\n",
    "\n",
    "dataset = dataset_manager.preload_data(selected_runs, features=inputs+outputs)\n",
    "N_s = dataset_manager.count_states()\n",
    "train, test = train_test_split(dataset, test_size=0.2, random_state=44)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame(columns=['Data Set', 'Name', 'regularization', 'd', 'w', 'Precision', 'Recall'])\n",
    "# results_df = results_df.set_index(['Data Set', 'Name', 'w'])\n",
    "results_df = pd.read_csv('tree_results_20.csv', index_col=0).append(pd.read_csv('results_3_5_10_15.csv', index_col=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def class_precision_recall(y_true, y_pred):\n",
    "    # _, classes = y_pred.shape\n",
    "\n",
    "    # y_true = tf.math.argmax(y_true, axis=-1)  # batch x L\n",
    "    # y_pred = tf.math.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    y_true = tf.constant(y_true)\n",
    "    y_pred = tf.constant(y_pred)\n",
    "    \n",
    "    classes = N_s\n",
    "\n",
    "    y_pred.shape.assert_is_compatible_with(y_true.shape)\n",
    "    if y_true.dtype != y_pred.dtype:\n",
    "        y_pred = tf.cast(y_pred, y_true.dtype)\n",
    "\n",
    "    recall_scores, precision_scores = [], []\n",
    "    for C in range(classes):\n",
    "        C = tf.cast(C, 'int64')\n",
    "        trueC = tf.equal(y_true, C)\n",
    "        declaredC = tf.equal(y_pred, C)\n",
    "        correctlyC = tf.logical_and(declaredC, trueC)\n",
    "\n",
    "        trueC = tf.cast(tf.math.count_nonzero(trueC), 'float32')\n",
    "        declaredC = tf.cast(tf.math.count_nonzero(declaredC), 'float32')\n",
    "        correctlyC = tf.cast(tf.math.count_nonzero(correctlyC), 'float32')\n",
    "\n",
    "        if declaredC > 0:\n",
    "            precision_score = tf.math.divide_no_nan(correctlyC, declaredC)\n",
    "            precision_scores.append(precision_score)\n",
    "        if trueC > 0:\n",
    "            recall_score = tf.math.divide_no_nan(correctlyC, trueC)\n",
    "            recall_scores.append(recall_score)\n",
    "\n",
    "    P = tf.reduce_mean(tf.stack(precision_scores))\n",
    "    R = tf.reduce_mean(tf.stack(recall_scores))\n",
    "    \n",
    "    return P, R\n",
    "\n",
    "def iterate_window(dataframe, w):\n",
    "    last = dataframe.shape[0] - w + 1\n",
    "    for index in range(last):\n",
    "        yield dataframe[index:index+w]\n",
    "\n",
    "def convert_to_data_points(w):\n",
    "    def _generator(data):\n",
    "        signals = data[1].to_numpy()\n",
    "        states = data[2].to_numpy()\n",
    "        signals_iter = iterate_window(signals, w)\n",
    "        # previous_iter = iterate_window(states, w)\n",
    "        next_state_iter = states[w:]\n",
    "        \n",
    "        # for signals, previous, next_state in zip(signals_iter, previous_iter, next_state_iter):\n",
    "        for signals, next_state in zip(signals_iter, next_state_iter):\n",
    "            # X = np.concatenate((signals.flatten(), one_hotter[previous].flatten()))\n",
    "            X = signals.flatten()\n",
    "            # y = one_hotter[next_state]\n",
    "            y = next_state\n",
    "            yield X, y\n",
    "\n",
    "    return _generator\n",
    "\n",
    "def create_allX_allY(dataset, w):\n",
    "    converter = convert_to_data_points(w)\n",
    "    allX, allY = [], []\n",
    "    for test in tqdm.tqdm(dataset):\n",
    "        lX, ly = [], []\n",
    "        for X, y in converter(test):\n",
    "            lX.append(X)\n",
    "            ly.append(y)\n",
    "        allX.append(np.stack(lX))\n",
    "        allY.append(np.stack(ly))\n",
    "        del lX, ly\n",
    "    \n",
    "    # return allX, allY\n",
    "    return np.concatenate(allX), np.concatenate(allY)\n",
    "\n",
    "def evaluate(model, *, name, w, regularization, d):\n",
    "    train_p, train_r = class_precision_recall(y_train, model.predict(X_train))\n",
    "    test_p, test_r = class_precision_recall(y_test, model.predict(X_test))\n",
    "    df = pd.DataFrame({\n",
    "        'Data Set': ['Train', 'Test'], \n",
    "        'Precision': [float(train_p), float(test_p)],\n",
    "        'Recall': [float(train_r), float(test_r)],\n",
    "    })\n",
    "    df['Name'] = name\n",
    "    df['w'] = w\n",
    "    df['d'] = d\n",
    "    df['regularization'] = regularization\n",
    "    # df = df.set_index(['Data Set', 'Name', 'w'])\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w=20\n",
    "X_train, y_train = create_allX_allY(train, w)\n",
    "X_test, y_test = create_allX_allY(test, w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_ridge = linear_model.RidgeClassifierCV(alphas=np.logspace(-6, 6, 13))\n",
    "model_ridge.fit(X_train, y_train)\n",
    "results = evaluate(model_ridge, name='ridge', w=w, regularization=None, d=None)\n",
    "results_df = results_df.append(results)\n",
    "display(results)\n",
    "\n",
    "# model_tree = tree.DecisionTreeClassifier(max_features=None, max_depth=None)\n",
    "# model_tree.fit(X_train, y_train)\n",
    "# results = evaluate(model_tree, name='tree', regularization=None, w=w, d=None)\n",
    "# results_df = results_df.append(results)\n",
    "# display(results)\n",
    "# display(model_tree.get_depth(), model_tree.get_n_leaves())\n",
    "# \n",
    "# model_tree = tree.DecisionTreeClassifier(max_features='sqrt', max_depth=None)\n",
    "# model_tree.fit(X_train, y_train)\n",
    "# results = evaluate(model_tree, name='tree', regularization='sqrt', w=w, d=None)\n",
    "# results_df = results_df.append(results)\n",
    "# display(results)\n",
    "# display(model_tree.get_depth(), model_tree.get_n_leaves())\n",
    "# \n",
    "# model_tree = tree.DecisionTreeClassifier(max_features='log2', max_depth=None)\n",
    "# model_tree.fit(X_train, y_train)\n",
    "# results = evaluate(model_tree, name='tree', regularization='log2', w=w, d=None)\n",
    "# results_df = results_df.append(results)\n",
    "# display(results)\n",
    "# display(model_tree.get_depth(), model_tree.get_n_leaves())\n",
    "\n",
    "# results_df.to_csv('tree_results_15.csv')\n",
    "\n",
    "# del X_train, X_test, y_train, y_test\n",
    "\n",
    "results_df.loc[(results_df['Data Set'] == 'Test') & (results_df['w'] == w)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# results_df.loc['Test',results_df.reset_index()['Name'].str.contains('log2'), 5]\n",
    "# results_df.loc[(results_df['Data Set'] == 'Test') & (results_df['w'] == w) & (results_df['regularization'] == 'log2')] \\\n",
    "#     .sort_values(['d', 'regularization'])\n",
    "results_df.loc[(results_df['Data Set'] == 'Test') & (results_df['w'] == w)].sort_values(['regularization'])\n",
    "# results_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_df['Precision'] *= 100\n",
    "results_df['Recall'] *= 100\n",
    "results_df['F1'] = 2*results_df['Precision']*results_df['Recall'] / (results_df['Precision']+results_df['Recall'])\n",
    "test_results = results_df.loc[results_df['Data Set'] == 'Test'].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ridge_results = test_results.loc[test_results['Name'] == 'ridge']\n",
    "ridge_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_results = test_results.loc[test_results['Name'] == 'tree']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_results.loc[tree_results['w'] == 3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_results.loc[tree_results['w'] == 5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_results.loc[tree_results['w'] == 10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_results.loc[tree_results['w'] == 15]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_results.loc[tree_results['w'] == 20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_results.loc[tree_results.groupby(['w'])['F1'].transform(max) == tree_results['F1']].sort_values('w')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ridge_results.loc[ridge_results.groupby(['w'])['F1'].transform(max) == ridge_results['F1']].sort_values('w')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_df.shape\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}